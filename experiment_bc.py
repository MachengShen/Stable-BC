"""
Behavior Cloning with Denoising Autoencoder

This experiment demonstrates the use of a denoising autoencoder to mitigate the covariate shift issue in behavior cloning for a simple 2D trajectory tracking task.

The main components of this experiment are:

1. Trajectory Simulation:
   A 2D sinusoidal trajectory is simulated using the `simulate_trajectory` function. This trajectory serves as the ground truth for the task.

2. Dataset Creation:
   Two datasets are created from the simulated trajectory:
   - Clean Dataset: Created using `create_clean_dataset`, this dataset contains pairs of consecutive states (current state, next state) from the ground truth trajectory.
   - Noisy Dataset: Created using `create_noisy_dataset`, this dataset contains pairs of noisy states and their corresponding clean states. The noisy states are generated by adding random Gaussian noise to the clean states. Multiple noisy samples are generated for each clean sample to cover a wider range of the noise distribution.

3. Model Architectures:
   - Behavior Cloning MLP: A simple multilayer perceptron (MLP) model is used for behavior cloning. It takes the current state as input and predicts the next state.
   - Denoising Autoencoder: An autoencoder model with an encoder and a decoder is used for denoising. It takes the concatenation of the noisy current state and the noisy next state as input and outputs the denoised current state and the denoised next state.

4. Training:
   - Behavior Cloning: The MLP model is trained using the clean dataset, minimizing the mean squared error (MSE) between the predicted next state and the ground truth next state.
   - Denoising Autoencoder: The denoising autoencoder is trained using the noisy dataset, minimizing the MSE between the denoised outputs and the corresponding clean states.

5. Trajectory Generation and Visualization:
   Three trajectories are generated and visualized:
   - Ground Truth Trajectory: The original simulated trajectory.
   - Behavior Cloning Trajectory: Generated by recursively applying the behavior cloning MLP model on the previous state.
   - Denoised Behavior Cloning Trajectory: Generated by applying the behavior cloning MLP model on the denoised state from the previous step, and then denoising the output using the denoising autoencoder.

The main goal of this experiment is to demonstrate how the denoising autoencoder can help mitigate the covariate shift issue in behavior cloning by denoising the outputs of the behavior cloning model, leading to a trajectory that is closer to the ground truth.

Note: This experiment assumes a simple 2D trajectory tracking task. In more complex scenarios, additional techniques or modifications may be required to handle the covariate shift issue effectively.
"""

import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from torch.nn.utils import spectral_norm

# Simulate a simple 2D sinusoidal trajectory
def simulate_trajectory(num_samples, amplitude=1.0, freq=1.0, random_sampling=False):
    """
    Simulate a simple 2D sinusoidal trajectory with optional random time steps.

    Args:
        num_samples (int): The number of samples in the trajectory.
        amplitude (float, optional): The amplitude of the sinusoidal curve. Default is 1.0.
        freq (float, optional): The frequency of the sinusoidal curve. Default is 1.0.
        random_sampling (bool, optional): Whether to use random sampling for time steps. Default is False.

    Returns:
        np.ndarray: A 2D array representing the simulated trajectory, where each row is a (x, y, x_next, y_next) coordinate.
    """
    trajectory = []

    if random_sampling:
        for _ in range(num_samples):
            x = np.random.uniform(0, 2 * np.pi)
            y = amplitude * np.sin(freq * x)
            dt = np.random.uniform(0.09, 0.11)
            x_next = x + dt
            y_next = amplitude * np.sin(freq * x_next)
            trajectory.append((x, y, x_next, y_next))
    else:
        t = np.linspace(0, 2 * np.pi, num_samples + 1)[:-1]
        x = t
        y = amplitude * np.sin(freq * t)
        x_next = t + 0.1
        y_next = amplitude * np.sin(freq * x_next)
        trajectory = np.column_stack((x, y, x_next, y_next))

    trajectory[:, 0] = trajectory[:, 0] / 3.0 - 1.5
    trajectory[:, 2] = trajectory[:, 2] / 3.0 - 1.5
    return np.array(trajectory)

def create_clean_dataset(trajectory):
    """
    Create a dataset from the simulated trajectory.

    Args:
        trajectory (np.ndarray): The simulated trajectory.

    Returns:
        tuple: A tuple containing two numpy arrays (X, Y), where X is the input data (current states)
               and Y is the output data (next states).
    """
    X = trajectory[:, :2]
    Y = trajectory[:, 2:]
    return X, Y

# Create a augment dataset from the clean data (adding noise to current state)
def create_augment_dataset(X, Y, noise_factor=0.1, num_noisy_samples=10):
    X_aug, Y_aug = [], []
    for x, y in zip(X, Y):
        for _ in range(num_noisy_samples):
            noise_x = noise_factor * np.random.normal(loc=0.0, scale=1.0, size=2)
            noisy_x = x + noise_x
            X_aug.append(noisy_x)
            Y_aug.append(y)
    return np.array(X_aug), np.array(Y_aug)

# Create a denoisingAE dataset from the clean data
def create_denoisingAE_dataset(X, Y, noise_factor=[0.1, 0.1], num_noisy_samples=10):
    # input X is the concat of noisy version of current state and next state
    # output Y is the concat of clearn version of current state and next state
    X_noisy, Y_noisy = [], []
    for x, y in zip(X, Y):
        for _ in range(num_noisy_samples):
            noise_x = noise_factor[0] * np.random.normal(loc=0.0, scale=1.0, size=2)
            noise_y = noise_factor[1] * np.random.normal(loc=0.0, scale=1.0, size=2)
            noisy_x = x + noise_x
            noisy_y = y + noise_y
            X_noisy.append(np.concatenate((noisy_x, noisy_y)))
            Y_noisy.append(np.concatenate((x, y)))
    return np.array(X_noisy), np.array(Y_noisy)

# Define the MLP model for behavior cloning
class BehaviorCloningMLP(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(BehaviorCloningMLP, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)  # New middle layer
        self.fc3 = nn.Linear(hidden_size, output_size)  # Renamed from fc2 to fc3

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))  # New middle layer activation
        x = self.fc3(x)
        return x

# Define the denoising autoencoder
class DenoisingAutoencoder(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, use_spectral_norm=False, use_residual=False):
        super(DenoisingAutoencoder, self).__init__()
        
        # Helper function to optionally apply spectral norm
        def maybe_spectral_norm(layer):
            return spectral_norm(layer) if use_spectral_norm else layer
        
        # Encoder with optional spectral normalization
        self.encoder = nn.Sequential(
            maybe_spectral_norm(nn.Linear(input_size, hidden_size)),
            nn.ReLU(),
            maybe_spectral_norm(nn.Linear(hidden_size, output_size)),
            nn.ReLU(),
        )
        
        # Decoder with optional spectral normalization
        self.decoder = nn.Sequential(
            maybe_spectral_norm(nn.Linear(output_size, hidden_size)),
            nn.ReLU(),
            maybe_spectral_norm(nn.Linear(hidden_size, 2))  # Only output the next state (2D)
        )
        
        self.use_residual = use_residual

    def forward(self, x):
        # Split input into current state and noisy next state
        current_state, noisy_next_state = torch.split(x, [x.shape[1] - 2, 2], dim=1)
        
        # Pass through encoder-decoder
        encoded = self.encoder(x)
        denoised_delta = self.decoder(encoded)  # This is now a correction term
        
        # Optionally add residual connection
        if self.use_residual:
            denoised_next_state = noisy_next_state + denoised_delta
        else:
            denoised_next_state = denoised_delta
        
        return denoised_next_state

# Train the MLP using behavior cloning
def train_behavior_cloning(X, Y, num_epochs=100, batch_size=32, hidden_size=64):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)
    Y_tensor = torch.tensor(Y, dtype=torch.float32).to(device)
    dataset = TensorDataset(X_tensor, Y_tensor)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    input_size = X.shape[-1]
    output_size = Y.shape[-1]
    model = BehaviorCloningMLP(input_size, hidden_size, output_size).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters())

    for epoch in range(num_epochs):
        for inputs, targets in dataloader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

        if (epoch + 1) % 2 == 0:
            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

    return model

# Train the denoising autoencoder
def train_denoising_autoencoder(X_noisy, Y_noisy, num_epochs=100, batch_size=32, hidden_size=64, 
                              use_spectral_norm=False, use_residual=False, lr=1e-4):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    X_noisy_tensor = torch.tensor(X_noisy, dtype=torch.float32).to(device)
    Y_noisy_tensor = torch.tensor(Y_noisy, dtype=torch.float32).to(device)

    dataset = TensorDataset(X_noisy_tensor, Y_noisy_tensor)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    input_size = X_noisy.shape[-1]
    output_size = Y_noisy.shape[-1] // 2
    model = DenoisingAutoencoder(input_size, hidden_size, output_size, 
                                use_spectral_norm=use_spectral_norm, 
                                use_residual=use_residual).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    for epoch in range(num_epochs):
        for inputs, targets in dataloader:
            optimizer.zero_grad()
            denoised_next_state = model(inputs)
            # Only compare with the next state part of the targets
            _, target_next_state = torch.split(targets, [targets.shape[1] - 2, 2], dim=1)
            loss = criterion(denoised_next_state, target_next_state)
            loss.backward()
            optimizer.step()

        if (epoch + 1) % 2 == 0:
            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

    return model

# Visualize the trajectories
def visualize_trajectories(bc_model, denoising_model, bc_augment_model, ground_truth, initial_state, num_steps):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    ground_truth_trajectory = ground_truth
    bc_trajectory = [initial_state]
    bc_augment_trajectory = [initial_state]
    denoised_trajectory = [initial_state]

    bc_state = torch.tensor(initial_state, dtype=torch.float32).unsqueeze(0).to(device)
    bc_augment_state = torch.tensor(initial_state, dtype=torch.float32).unsqueeze(0).to(device)
    denoised_state = torch.tensor(initial_state, dtype=torch.float32).unsqueeze(0).to(device)

    with torch.no_grad():
        for _ in range(num_steps - 1):
            # Generate behavior cloning trajectory
            bc_next_state = bc_model(bc_state)
            bc_trajectory.append(bc_next_state.cpu().squeeze().numpy())
            bc_state = bc_next_state
            
            # Generate behavior cloning trajectory with noisy X
            bc_augment_next_state = bc_augment_model(bc_augment_state)
            bc_augment_trajectory.append(bc_augment_next_state.cpu().squeeze().numpy())
            bc_augment_state = bc_augment_next_state

            # Generate denoised trajectory
            bc_next_state_from_denoised = bc_model(denoised_state)
            print(f"step{_}: bc_next_state_from_denoised={bc_next_state_from_denoised.cpu()}")
            
            denoising_input = torch.cat([denoised_state, bc_next_state_from_denoised], dim=1)
            denoised_next_state = denoising_model(denoising_input)
            print(f"step{_}: denoised_next_state={denoised_next_state.cpu()}")
            denoised_trajectory.append(denoised_next_state.cpu().squeeze().numpy())
            denoised_state = denoised_next_state

    bc_trajectory = np.array(bc_trajectory)
    print(f"bc_trajectory: {bc_trajectory}")
    bc_augment_trajectory = np.array(bc_augment_trajectory)
    print(f"bc_augment_trajectory: {bc_augment_trajectory}")
    denoised_trajectory = np.array(denoised_trajectory)
    print(f"denoised_tratectory: {denoised_trajectory}")

    plt.figure(figsize=(8, 6))
    plt.scatter(ground_truth_trajectory[:, 0], ground_truth_trajectory[:, 1], marker='o', s=10, label='Ground Truth')
    plt.plot(bc_trajectory[:, 0], bc_trajectory[:, 1], label='Behavior Cloning')
    plt.plot(bc_augment_trajectory[:, 0], bc_augment_trajectory[:, 1], label='Behavior Cloning with noisy input')
    plt.plot(denoised_trajectory[:, 0], denoised_trajectory[:, 1], label='Denoised Behavior Cloning')
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title('Trajectories Comparison')
    plt.legend()
    plt.tight_layout()
    plt.savefig('trajectories.png', dpi=300, bbox_inches='tight')
    plt.close()

def visualize_flow_field(bc_model, denoising_model, bounds=None, n_points=200):
    """
    Visualize the flow field of the composite mapping (BC + Denoising).
    
    Args:
        bc_model: The behavior cloning model
        denoising_model: The denoising autoencoder model
        bounds: Tuple of ((x_min, x_max), (y_min, y_max)) for the plot bounds
        n_points: Number of points in each dimension for the grid
    """
    if bounds is None:
        bounds = ((-2, 2), (-2, 2))
    
    # Create a grid of points
    x = np.linspace(bounds[0][0], bounds[0][1], n_points)
    y = np.linspace(bounds[1][0], bounds[1][1], n_points)
    X, Y = np.meshgrid(x, y)
    
    # Prepare grid points as input
    grid_points = np.column_stack((X.flatten(), Y.flatten()))
    
    # Convert to tensor
    grid_tensor = torch.tensor(grid_points, dtype=torch.float32)
    
    # Get the flow vectors
    with torch.no_grad():
        # Apply BC model
        bc_output = bc_model(grid_tensor)
        
        # Prepare input for denoising model
        denoising_input = torch.cat([grid_tensor, bc_output], dim=1)
        
        # Apply denoising model
        _, denoised_next_state = denoising_model(denoising_input)
    
    # Calculate displacement vectors
    flow_vectors = denoised_next_state.numpy() - grid_points
    
    # Reshape for plotting
    U = flow_vectors[:, 0].reshape(n_points, n_points)
    V = flow_vectors[:, 1].reshape(n_points, n_points)
    
    # Create the visualization
    plt.figure(figsize=(10, 8))
    
    # Plot streamlines
    plt.streamplot(X, Y, U, V, density=1.5, color='blue', linewidth=1, arrowsize=1)
    
    # Add a scatter plot of some sample points and their transitions
    sample_indices = np.random.choice(len(grid_points), 50)
    sample_points = grid_points[sample_indices]
    sample_next_points = denoised_next_state.numpy()[sample_indices]
    
    plt.scatter(sample_points[:, 0], sample_points[:, 1], 
               c='red', s=30, alpha=0.5, label='Start points')
    plt.scatter(sample_next_points[:, 0], sample_next_points[:, 1], 
               c='green', s=30, alpha=0.5, label='End points')
    
    # Add arrows connecting some points
    for start, end in zip(sample_points, sample_next_points):
        plt.arrow(start[0], start[1], 
                 end[0]-start[0], end[1]-start[1],
                 head_width=0.05, head_length=0.1, 
                 fc='gray', ec='gray', alpha=0.3)
    
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title('Flow Field of Composite Mapping (BC + Denoising)')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('flow_field.png', dpi=300, bbox_inches='tight')
    plt.close()

def visualize_multiple_trajectories_comparison(bc_model, denoising_model, ground_truth, 
                                            center_point, radius=0.1, num_trajectories=20, 
                                            num_steps=100):
    """
    Compare multiple trajectories between BC-only and BC+Denoising settings.
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
    
    # Generate random initial points within a circle
    angles = np.random.uniform(0, 2*np.pi, num_trajectories)
     # use radius / 2.0 as lower bound to avoid too small
    distances = np.random.uniform(radius / 2.0, radius, num_trajectories)
    initial_points = np.array([
        center_point + [distances[i] * np.cos(angles[i]), 
                       distances[i] * np.sin(angles[i])]
        for i in range(num_trajectories)
    ])
    
    # Generate trajectories for both settings
    bc_trajectories = []
    composite_trajectories = []
    
    with torch.no_grad():
        for init_point in initial_points:
            # BC-only trajectory
            bc_trajectory = [init_point]
            current_state = torch.tensor(init_point, dtype=torch.float32).unsqueeze(0)
            
            for _ in range(num_steps):
                bc_output = bc_model(current_state)
                bc_trajectory.append(bc_output.squeeze().numpy())
                current_state = bc_output
            
            bc_trajectories.append(np.array(bc_trajectory))
            
            # BC+Denoising trajectory
            composite_trajectory = [init_point]
            current_state = torch.tensor(init_point, dtype=torch.float32).unsqueeze(0)
            
            for _ in range(num_steps):
                bc_output = bc_model(current_state)
                denoising_input = torch.cat([current_state, bc_output], dim=1)
                _, denoised_next_state = denoising_model(denoising_input)
                composite_trajectory.append(denoised_next_state.squeeze().numpy())
                current_state = denoised_next_state
            
            composite_trajectories.append(np.array(composite_trajectory))
    
    # Plot BC-only trajectories
    ax1.scatter(ground_truth[:, 0], ground_truth[:, 1], 
               color='gray', alpha=0.3, s=10, label='Ground Truth')
    
    init_points = np.array([traj[0] for traj in bc_trajectories])
    ax1.scatter(init_points[:, 0], init_points[:, 1], 
               color='red', s=50, label='Initial Points')
    
    colors = plt.cm.rainbow(np.linspace(0, 1, num_trajectories))
    for traj, color in zip(bc_trajectories, colors):
        ax1.plot(traj[:, 0], traj[:, 1], color=color, alpha=0.5, linewidth=1)
    
    final_points = np.array([traj[-1] for traj in bc_trajectories])
    ax1.scatter(final_points[:, 0], final_points[:, 1], 
               color='green', s=50, label='Final Points')
    
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_title('BC-only Trajectories')
    ax1.legend()
    ax1.grid(True)
    
    # Plot BC+Denoising trajectories
    ax2.scatter(ground_truth[:, 0], ground_truth[:, 1], 
               color='gray', alpha=0.3, s=10, label='Ground Truth')
    
    init_points = np.array([traj[0] for traj in composite_trajectories])
    ax2.scatter(init_points[:, 0], init_points[:, 1], 
               color='red', s=50, label='Initial Points')
    
    for traj, color in zip(composite_trajectories, colors):
        ax2.plot(traj[:, 0], traj[:, 1], color=color, alpha=0.5, linewidth=1)
    
    final_points = np.array([traj[-1] for traj in composite_trajectories])
    ax2.scatter(final_points[:, 0], final_points[:, 1], 
               color='green', s=50, label='Final Points')
    
    ax2.set_xlabel('X')
    ax2.set_ylabel('Y')
    ax2.set_title('BC+Denoising Trajectories')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('multiple_trajectories_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # Plot convergence analysis
    plt.figure(figsize=(12, 4))
    
    # Calculate distances for BC-only
    bc_distances = []
    for traj in bc_trajectories:
        distances = np.sqrt(np.sum(np.diff(traj, axis=0)**2, axis=1))
        bc_distances.append(distances)
    
    bc_distances = np.array(bc_distances)
    bc_mean = np.mean(bc_distances, axis=0)
    bc_std = np.std(bc_distances, axis=0)
    
    # Calculate distances for BC+Denoising
    composite_distances = []
    for traj in composite_trajectories:
        distances = np.sqrt(np.sum(np.diff(traj, axis=0)**2, axis=1))
        composite_distances.append(distances)
    
    composite_distances = np.array(composite_distances)
    composite_mean = np.mean(composite_distances, axis=0)
    composite_std = np.std(composite_distances, axis=0)
    
    time_steps = np.arange(len(bc_mean))
    
    plt.plot(time_steps, bc_mean, label='BC-only (Mean)', color='blue')
    plt.fill_between(time_steps, 
                     bc_mean - bc_std, 
                     bc_mean + bc_std, 
                     color='blue', alpha=0.3)
    
    plt.plot(time_steps, composite_mean, label='BC+Denoising (Mean)', color='orange')
    plt.fill_between(time_steps, 
                     composite_mean - composite_std, 
                     composite_mean + composite_std, 
                     color='orange', alpha=0.3)
    
    plt.xlabel('Time Step')
    plt.ylabel('Distance Between Consecutive Points')
    plt.title('Convergence Analysis Comparison')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('convergence_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()

def visualize_local_contraction_comparison(bc_model, denoising_model, train_points, 
                                         num_sample_points=5, num_local_samples=20, 
                                         radius=0.05):
    """
    Compare local contraction properties between BC-only and BC+Denoising mappings.
    """
    # Randomly sample some training points
    indices = np.random.choice(len(train_points), num_sample_points, replace=False)
    sample_points = train_points[indices]
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
    
    # Generate and plot for both mappings
    colors = plt.cm.rainbow(np.linspace(0, 1, num_sample_points))
    
    # Plot all training points as background in both plots
    for ax in [ax1, ax2]:
        ax.scatter(train_points[:, 0], train_points[:, 1], 
                  color='gray', alpha=0.1, s=5, label='Training Points')
    
    with torch.no_grad():
        for i, center in enumerate(sample_points):
            # Generate local samples
            angles = np.random.uniform(0, 2*np.pi, num_local_samples)
            # use radius / 2.0 as lower bound to avoid too small
            distances = np.random.uniform(radius / 2.0, radius, num_local_samples)
            local_samples = np.array([
                center + [distances[j] * np.cos(angles[j]), 
                       distances[j] * np.sin(angles[j])]
                for j in range(num_local_samples)
            ])
            
            # Convert to tensor
            local_samples_tensor = torch.tensor(local_samples, dtype=torch.float32)
            
            # BC-only mapping
            bc_output = bc_model(local_samples_tensor)
            bc_mapped = bc_output.numpy()
            
            # BC+Denoising mapping
            denoising_input = torch.cat([local_samples_tensor, bc_output], dim=1)
            composite_mapped = denoising_model(denoising_input)
            composite_mapped = composite_mapped.numpy()
            
            # Plot BC-only mapping (left plot)
            ax1.scatter(local_samples[:, 0], local_samples[:, 1], 
                       color=colors[i], alpha=0.3, s=15)
            ax1.scatter(center[0], center[1], color=colors[i], 
                       s=50, marker='*', label=f'Center {i+1}')
            
            # Draw arrows from input to output
            for start, end in zip(local_samples, bc_mapped):
                ax1.arrow(start[0], start[1], 
                         end[0]-start[0], end[1]-start[1],
                         head_width=0.02, head_length=0.03, 
                         fc=colors[i], ec=colors[i], alpha=0.2)
            
            # Calculate and plot centroid of mapped points
            bc_centroid = np.mean(bc_mapped, axis=0)
            ax1.scatter(bc_centroid[0], bc_centroid[1], color=colors[i], 
                       s=50, marker='o')
            
            # Calculate BC-only contraction ratio
            input_distances = np.linalg.norm(local_samples - center, axis=1)
            output_distances = np.linalg.norm(bc_mapped - bc_centroid, axis=1)
            bc_ratio = np.mean(output_distances) / np.mean(input_distances)
            
            # Plot BC+Denoising mapping (right plot)
            ax2.scatter(local_samples[:, 0], local_samples[:, 1], 
                       color=colors[i], alpha=0.3, s=15)
            ax2.scatter(center[0], center[1], color=colors[i], 
                       s=50, marker='*', label=f'Center {i+1}')
            
            # Draw arrows from input to output
            for start, end in zip(local_samples, composite_mapped):
                ax2.arrow(start[0], start[1], 
                         end[0]-start[0], end[1]-start[1],
                         head_width=0.02, head_length=0.03, 
                         fc=colors[i], ec=colors[i], alpha=0.2)
            
            # Calculate and plot centroid of mapped points
            composite_centroid = np.mean(composite_mapped, axis=0)
            ax2.scatter(composite_centroid[0], composite_centroid[1], 
                       color=colors[i], s=50, marker='o')
            
            # Calculate composite mapping contraction ratio
            output_distances = np.linalg.norm(composite_mapped - composite_centroid, axis=1)
            composite_ratio = np.mean(output_distances) / np.mean(input_distances)
            
            print(f"Region {i+1} - Contraction ratios:")
            print(f"  BC-only: {bc_ratio:.3f}")
            print(f"  BC+Denoising: {composite_ratio:.3f}")
    
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_title('BC-only Mapping')
    ax1.legend()
    ax1.grid(True)
    
    ax2.set_xlabel('X')
    ax2.set_ylabel('Y')
    ax2.set_title('BC+Denoising Mapping')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('local_contraction_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()

def analyze_sensitivity_and_lipschitz(bc_model, denoising_model, train_points, train_next_points,
                                   num_sample_points=5, num_local_samples=20, 
                                   radius=0.05):
    """
    Analyze both sensitivity and Lipschitz constants using the same sampled points.
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    bc_model = bc_model.to(device)
    denoising_model = denoising_model.to(device)
    
    # Randomly sample some training points
    indices = np.random.choice(len(train_points), num_sample_points, replace=False)
    sample_points = train_points[indices]
    sample_next_points = train_next_points[indices]
    
    # Initialize arrays to store metrics for each region
    bc_sensitivities = []
    composite_sensitivities = []
    lipschitz_xt1_values = []
    lipschitz_xt_values = []
    
    # Create figures for both analyses
    fig_sens, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
    fig_lip, ax_lip = plt.subplots(figsize=(12, 8))
    
    # Plot all training points as background
    for ax in [ax1, ax2, ax_lip]:
        ax.scatter(train_points[:, 0], train_points[:, 1], 
                  color='lightgray', alpha=0.1, s=5, label='Training Points')
    
    # Add shape indicators to legend once (will be copied to other plots)
    ax1.scatter([], [], color='black', marker='*', s=100, label='x_t (★)')
    ax1.scatter([], [], color='black', marker='^', s=100, label='True x_t+1 (��)')
    ax1.scatter([], [], color='black', marker='o', s=100, label='Output Centroid (●)')
    ax1.scatter([], [], color='black', alpha=0.3, s=15, label='Perturbed Points')
    
    # Get legend handles and labels to copy later
    handles, labels = ax1.get_legend_handles_labels()
    
    colors = plt.cm.rainbow(np.linspace(0, 1, num_sample_points))
    
    with torch.no_grad():
        for i, (x_t, true_next) in enumerate(zip(sample_points, sample_next_points)):
            # Generate perturbed x_t points
            angles = np.random.uniform(0, 2*np.pi, num_local_samples)
            distances = np.random.uniform(radius / 2.0, radius, num_local_samples)
            perturbed_xt = np.array([
                x_t + [distances[j] * np.cos(angles[j]), 
                      distances[j] * np.sin(angles[j])]
                for j in range(num_local_samples)
            ])
            
            # Convert to tensors and move to device
            perturbed_xt_tensor = torch.tensor(perturbed_xt, dtype=torch.float32).to(device)
            x_t_tensor = torch.tensor(x_t, dtype=torch.float32).to(device)
            true_next_tensor = torch.tensor(true_next, dtype=torch.float32).to(device)
            
            # BC-only mapping
            bc_output = bc_model(perturbed_xt_tensor)
            bc_output_numpy = bc_output.cpu().numpy()
            
            # BC+Denoising mapping
            denoising_input = torch.cat([perturbed_xt_tensor, bc_output], dim=1)
            denoised_next = denoising_model(denoising_input)
            denoised_next_numpy = denoised_next.cpu().numpy()
            
            # Plot BC-only results (left plot)
            ax1.scatter(x_t[0], x_t[1], color=colors[i], s=100, marker='*')
            ax1.scatter(true_next[0], true_next[1], color=colors[i], s=100, marker='^')
            ax1.scatter(perturbed_xt[:, 0], perturbed_xt[:, 1], 
                      color=colors[i], alpha=0.3, s=15)
            
            for start, end in zip(perturbed_xt, bc_output_numpy):
                ax1.arrow(start[0], start[1], 
                        end[0]-start[0], end[1]-start[1],
                        head_width=0.02, head_length=0.03, 
                        fc=colors[i], ec=colors[i], alpha=0.2)
            
            bc_centroid = np.mean(bc_output_numpy, axis=0)
            ax1.scatter(bc_centroid[0], bc_centroid[1], 
                      color=colors[i], s=100, marker='o')
            
            # Calculate BC-only sensitivity
            bc_input_perturbations = np.linalg.norm(perturbed_xt - x_t, axis=1)
            bc_output_perturbations = np.linalg.norm(bc_output_numpy - true_next, axis=1)
            bc_sensitivity_ratios = bc_output_perturbations / bc_input_perturbations
            bc_sensitivities.append({
                'mean': np.mean(bc_sensitivity_ratios),
                'median': np.median(bc_sensitivity_ratios),
                'max': np.max(bc_sensitivity_ratios)
            })
            
            # Plot BC+Denoising results (right plot)
            ax2.scatter(x_t[0], x_t[1], color=colors[i], s=100, marker='*')
            ax2.scatter(true_next[0], true_next[1], color=colors[i], s=100, marker='^')
            ax2.scatter(perturbed_xt[:, 0], perturbed_xt[:, 1], 
                      color=colors[i], alpha=0.3, s=15)
            
            for start, end in zip(perturbed_xt, denoised_next_numpy):
                ax2.arrow(start[0], start[1], 
                        end[0]-start[0], end[1]-start[1],
                        head_width=0.02, head_length=0.03, 
                        fc=colors[i], ec=colors[i], alpha=0.2)
            
            denoised_centroid = np.mean(denoised_next_numpy, axis=0)
            ax2.scatter(denoised_centroid[0], denoised_centroid[1], 
                      color=colors[i], s=100, marker='o')
            
            # Calculate BC+Denoising sensitivity
            composite_output_perturbations = np.linalg.norm(denoised_next_numpy - true_next, axis=1)
            composite_sensitivity_ratios = composite_output_perturbations / bc_input_perturbations
            composite_sensitivities.append({
                'mean': np.mean(composite_sensitivity_ratios),
                'median': np.median(composite_sensitivity_ratios),
                'max': np.max(composite_sensitivity_ratios)
            })
            
            # Lipschitz Analysis
            # Generate perturbed x_t+1 points
            angles = np.random.uniform(0, 2*np.pi, num_local_samples)
            distances = np.random.uniform(radius / 2.0, radius, num_local_samples)
            perturbed_next = np.array([
                true_next + [distances[j] * np.cos(angles[j]), 
                           distances[j] * np.sin(angles[j])]
                for j in range(num_local_samples)
            ])
            
            # Apply denoising model with fixed x_t
            x_t_repeated = x_t_tensor.unsqueeze(0).repeat(num_local_samples, 1)
            perturbed_next_tensor = torch.tensor(perturbed_next, dtype=torch.float32).to(device)
            denoising_input = torch.cat([x_t_repeated, perturbed_next_tensor], dim=1)
            denoised_next = denoising_model(denoising_input)
            denoised_next_numpy = denoised_next.cpu().numpy()
            
            # Plot Lipschitz analysis
            ax_lip.scatter(x_t[0], x_t[1], color=colors[i], s=100, marker='*')
            ax_lip.scatter(true_next[0], true_next[1], color=colors[i], s=100, marker='^')
            ax_lip.scatter(perturbed_next[:, 0], perturbed_next[:, 1], 
                         color=colors[i], alpha=0.3, s=15)
            
            for start, end in zip(perturbed_next, denoised_next_numpy):
                ax_lip.arrow(start[0], start[1], 
                           end[0]-start[0], end[1]-start[1],
                           head_width=0.02, head_length=0.03, 
                           fc=colors[i], ec=colors[i], alpha=0.2)
            
            denoised_centroid = np.mean(denoised_next_numpy, axis=0)
            ax_lip.scatter(denoised_centroid[0], denoised_centroid[1], 
                         color=colors[i], s=100, marker='o')
            
            # Calculate Lipschitz constants
            input_perturbations_xt1 = np.linalg.norm(perturbed_next - true_next, axis=1)
            output_perturbations = np.linalg.norm(denoised_next_numpy - denoised_centroid, axis=1)
            lipschitz_constants_xt1 = output_perturbations / input_perturbations_xt1
            lipschitz_xt1_values.append({
                'mean': np.mean(lipschitz_constants_xt1),
                'median': np.median(lipschitz_constants_xt1),
                'max': np.max(lipschitz_constants_xt1)
            })
            
            # Calculate Lipschitz w.r.t x_t
            perturbed_xt_tensor = torch.tensor(perturbed_xt, dtype=torch.float32).to(device)
            true_next_repeated = true_next_tensor.unsqueeze(0).repeat(num_local_samples, 1)
            denoising_input_xt = torch.cat([perturbed_xt_tensor, true_next_repeated], dim=1)
            denoised_next_xt = denoising_model(denoising_input_xt)
            denoised_next_xt_numpy = denoised_next_xt.cpu().numpy()
            
            denoised_centroid_xt = np.mean(denoised_next_xt_numpy, axis=0)
            input_perturbations_xt = np.linalg.norm(perturbed_xt - x_t, axis=1)
            output_perturbations_xt = np.linalg.norm(denoised_next_xt_numpy - true_next, axis=1)
            lipschitz_constants_xt = output_perturbations_xt / input_perturbations_xt
            lipschitz_xt_values.append({
                'mean': np.mean(lipschitz_constants_xt),
                'median': np.median(lipschitz_constants_xt),
                'max': np.max(lipschitz_constants_xt)
            })
            
            print(f"Region {i+1} analysis:")
            print("  Sensitivity analysis:")
            print(f"    BC-only - Mean: {bc_sensitivities[-1]['mean']:.3f}, Median: {bc_sensitivities[-1]['median']:.3f}, Max: {bc_sensitivities[-1]['max']:.3f}")
            print(f"    BC+Denoising - Mean: {composite_sensitivities[-1]['mean']:.3f}, Median: {composite_sensitivities[-1]['median']:.3f}, Max: {composite_sensitivities[-1]['max']:.3f}")
            print("  Lipschitz analysis:")
            print(f"    w.r.t x_t+1 - Mean: {lipschitz_xt1_values[-1]['mean']:.3f}, Median: {lipschitz_xt1_values[-1]['median']:.3f}, Max: {lipschitz_xt1_values[-1]['max']:.3f}")
            print(f"    w.r.t x_t - Mean: {lipschitz_xt_values[-1]['mean']:.3f}, Median: {lipschitz_xt_values[-1]['median']:.3f}, Max: {lipschitz_xt_values[-1]['max']:.3f}")
    
    # Calculate and print average metrics across all regions
    print("\nAverage metrics across all regions:")
    print("Sensitivity analysis:")
    print("  BC-only:")
    print(f"    Mean: {np.mean([s['mean'] for s in bc_sensitivities]):.3f}")
    print(f"    Median: {np.mean([s['median'] for s in bc_sensitivities]):.3f}")
    print(f"    Max: {np.mean([s['max'] for s in bc_sensitivities]):.3f}")
    print("  BC+Denoising:")
    print(f"    Mean: {np.mean([s['mean'] for s in composite_sensitivities]):.3f}")
    print(f"    Median: {np.mean([s['median'] for s in composite_sensitivities]):.3f}")
    print(f"    Max: {np.mean([s['max'] for s in composite_sensitivities]):.3f}")
    print("Lipschitz analysis:")
    print("  w.r.t x_t+1:")
    print(f"    Mean: {np.mean([l['mean'] for l in lipschitz_xt1_values]):.3f}")
    print(f"    Median: {np.mean([l['median'] for l in lipschitz_xt1_values]):.3f}")
    print(f"    Max: {np.mean([l['max'] for l in lipschitz_xt1_values]):.3f}")
    print("  w.r.t x_t:")
    print(f"    Mean: {np.mean([l['mean'] for l in lipschitz_xt_values]):.3f}")
    print(f"    Median: {np.mean([l['median'] for l in lipschitz_xt_values]):.3f}")
    print(f"    Max: {np.mean([l['max'] for l in lipschitz_xt_values]):.3f}")
    
    # Set up plots with consistent legends
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_title('BC-only Sensitivity Analysis')
    ax1.legend(handles, labels)
    ax1.grid(True)
    
    ax2.set_xlabel('X')
    ax2.set_ylabel('Y')
    ax2.set_title('BC+Denoising Sensitivity Analysis')
    ax2.legend(handles, labels)
    ax2.grid(True)
    
    ax_lip.set_xlabel('X')
    ax_lip.set_ylabel('Y')
    ax_lip.set_title('Denoising Network Local Lipschitz Analysis')
    ax_lip.legend(handles, labels)
    ax_lip.grid(True)
    
    plt.tight_layout()
    plt.savefig('sensitivity_and_lipschitz.png', dpi=300, bbox_inches='tight')
    plt.close()

def train_denoising_autoencoder_with_loss_check(X_noisy, Y_noisy, num_epochs=100, batch_size=32, hidden_size=64, 
                                         use_spectral_norm=False, use_residual=False, lr=1e-4):
    """Modified training function that returns both model and average loss"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    X_noisy_tensor = torch.tensor(X_noisy, dtype=torch.float32).to(device)
    Y_noisy_tensor = torch.tensor(Y_noisy, dtype=torch.float32).to(device)

    dataset = TensorDataset(X_noisy_tensor, Y_noisy_tensor)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    input_size = X_noisy.shape[-1]
    output_size = Y_noisy.shape[-1] // 2
    model = DenoisingAutoencoder(input_size, hidden_size, output_size, 
                                use_spectral_norm=use_spectral_norm, 
                                use_residual=use_residual).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    losses = []
    for epoch in range(num_epochs):
        epoch_losses = []
        for inputs, targets in dataloader:
            optimizer.zero_grad()
            denoised_next_state = model(inputs)
            _, target_next_state = torch.split(targets, [targets.shape[1] - 2, 2], dim=1)
            loss = criterion(denoised_next_state, target_next_state)
            loss.backward()
            optimizer.step()
            epoch_losses.append(loss.item())
        
        avg_epoch_loss = np.mean(epoch_losses)
        losses.append(avg_epoch_loss)
        
        if (epoch + 1) % 2 == 0:
            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')

    avg_loss = np.mean(losses[-10:])  # Average of last 10 epochs
    return model, avg_loss

def analyze_sensitivity_vs_noise(bc_model, num_points=5, num_local_samples=20, radius=0.05):
    """
    Analyze how sensitivity reduction ratio changes with different noise factors.
    Uses rejection sampling to ensure good models for each noise level.
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    bc_model = bc_model.to(device)
    
    # Use linear-spaced noise factors up to 0.1 instead of 0.2
    noise_factors = np.linspace(0.005, 0.2, 10)  # Linear range from 0.01 to 0.1
    required_seeds = 3  # Number of successful seeds needed per noise level
    max_attempts = 20   # Maximum number of attempts per noise level
    loss_threshold = 1e-3  # Maximum acceptable loss
    
    # Store results for each seed
    all_reduction_ratios = []
    
    for noise_factor in noise_factors:
        print(f"\nAnalyzing noise factor: {noise_factor:.3f}")
        reduction_ratios_this_noise = []
        attempts = 0
        seed_base = 42
        
        while len(reduction_ratios_this_noise) < required_seeds and attempts < max_attempts:
            current_seed = seed_base + attempts
            print(f"Attempt {attempts + 1} with seed {current_seed}")
            
            # Set random seed
            np.random.seed(current_seed)
            torch.manual_seed(current_seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(current_seed)
                torch.cuda.manual_seed_all(current_seed)
            
            # Create new denoising model for this noise level
            X_denoisingAE, Y_denoisingAE = create_denoisingAE_dataset(X_clean, Y_clean, 
                                                                     noise_factor=[0.0, noise_factor], 
                                                                     num_noisy_samples=50)
            denoising_model, avg_loss = train_denoising_autoencoder_with_loss_check(
                X_denoisingAE, Y_denoisingAE, 
                num_epochs=300,
                use_spectral_norm=False,
                use_residual=False,
                lr=1e-4
            )
            denoising_model = denoising_model.to(device)
            
            print(f"Average loss: {avg_loss:.6f}")
            
            if avg_loss > loss_threshold:
                print(f"Rejecting model (loss = {avg_loss:.6f} > {loss_threshold})")
                attempts += 1
                continue
            
            print(f"Accepting model (loss = {avg_loss:.6f})")
            
            # Randomly sample points for analysis
            indices = np.random.choice(len(X_clean), num_points, replace=False)
            sample_points = X_clean[indices]
            sample_next_points = Y_clean[indices]
            
            bc_sensitivities = []
            composite_sensitivities = []
            
            with torch.no_grad():
                for x_t, true_next in zip(sample_points, sample_next_points):
                    # Generate perturbed points
                    angles = np.random.uniform(0, 2*np.pi, num_local_samples)
                    distances = np.random.uniform(0, radius, num_local_samples)
                    perturbed_xt = np.array([
                        x_t + [distances[j] * np.cos(angles[j]), 
                              distances[j] * np.sin(angles[j])]
                        for j in range(num_local_samples)
                    ])
                    
                    # BC-only mapping
                    perturbed_xt_tensor = torch.tensor(perturbed_xt, dtype=torch.float32).to(device)
                    bc_output = bc_model(perturbed_xt_tensor)
                    bc_output_numpy = bc_output.cpu().numpy()
                    
                    # BC+Denoising mapping
                    denoising_input = torch.cat([perturbed_xt_tensor, bc_output], dim=1)
                    denoised_next = denoising_model(denoising_input)
                    denoised_next = denoised_next.cpu().numpy()
                    
                    # Calculate sensitivities
                    bc_input_perturbations = np.linalg.norm(perturbed_xt - x_t, axis=1)
                    
                    bc_output_perturbations = np.linalg.norm(bc_output_numpy - true_next, axis=1)
                    bc_sensitivity_ratios = bc_output_perturbations / bc_input_perturbations
                    bc_sensitivities.append(np.mean(bc_sensitivity_ratios))
                    
                    composite_output_perturbations = np.linalg.norm(denoised_next - true_next, axis=1)
                    composite_sensitivity_ratios = composite_output_perturbations / bc_input_perturbations
                    composite_sensitivities.append(np.mean(composite_sensitivity_ratios))
            
            mean_bc = np.mean(bc_sensitivities)
            mean_denoising = np.mean(composite_sensitivities)
            reduction_ratio = mean_denoising / mean_bc
            reduction_ratios_this_noise.append(reduction_ratio)
            
            print(f"Reduction ratio: {reduction_ratio:.3f}")
            attempts += 1
        
        if len(reduction_ratios_this_noise) < required_seeds:
            print(f"Warning: Could only find {len(reduction_ratios_this_noise)} valid models for noise factor {noise_factor:.3f}")
        
        all_reduction_ratios.append(reduction_ratios_this_noise)
    
    # Process results, handling cases where we didn't get enough seeds
    mean_reduction_ratios = []
    std_reduction_ratios = []
    
    for ratios in all_reduction_ratios:
        if len(ratios) > 0:
            mean_reduction_ratios.append(np.mean(ratios))
            std_reduction_ratios.append(np.std(ratios) if len(ratios) > 1 else 0)
        else:
            mean_reduction_ratios.append(np.nan)
            std_reduction_ratios.append(np.nan)
    
    mean_reduction_ratios = np.array(mean_reduction_ratios)
    std_reduction_ratios = np.array(std_reduction_ratios)
    
    # Create the plot
    plt.figure(figsize=(10, 6))
    
    # Plot reduction ratio with error band
    plt.plot(noise_factors, mean_reduction_ratios, 'b-', label='Mean Reduction Ratio')
    plt.fill_between(noise_factors, 
                     mean_reduction_ratios - std_reduction_ratios,
                     mean_reduction_ratios + std_reduction_ratios,
                     color='b', alpha=0.2, label='±1 std')
    
    # Set labels (removed title, changed x-label)
    plt.xlabel('Noise STD')
    plt.ylabel('Sensitivity Reduction Ratio (Denoising/BC)')
    plt.grid(True)
    plt.legend()
    
    plt.tight_layout()
    plt.savefig('sensitivity_reduction_vs_noise.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # Print final statistics
    print("\nFinal statistics across accepted seeds:")
    for i, noise in enumerate(noise_factors):
        if not np.isnan(mean_reduction_ratios[i]):
            print(f"Noise factor {noise:.3f}:")
            print(f"  Mean reduction ratio: {mean_reduction_ratios[i]:.3f} ± {std_reduction_ratios[i]:.3f}")
            print(f"  (Using {len(all_reduction_ratios[i])} seeds)")
        else:
            print(f"Noise factor {noise:.3f}: No valid models found")

# Example usage
# Set random seeds for reproducibility
def seed_everything(seed=42):
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

if __name__ == "__main__":
    # need to normalize the states to ensure training performance!!
    
    seed_everything(7)
    random_sampling = False
    num_steps = 50
    # keep num_epochs low to ensure bc has covarite-shift problem
    num_epochs = 300
    ground_truth = simulate_trajectory(num_steps, random_sampling=random_sampling, freq=2.0)
    X_clean, Y_clean = create_clean_dataset(ground_truth)
    X_denoisingAE, Y_denoisingAE = create_denoisingAE_dataset(X_clean, Y_clean, noise_factor=[0.0, 0.05], num_noisy_samples=50) # 0.07 best
    X_augment, Y_augment = create_augment_dataset(X_clean, Y_clean, noise_factor=0.02, num_noisy_samples=50)
    print(f"X_noisy: {X_denoisingAE}; Y_noisy: {Y_denoisingAE}")
    bc_model = train_behavior_cloning(X_clean, Y_clean, num_epochs=num_epochs)
    bc_augment_model = train_behavior_cloning(X_augment, Y_augment, num_epochs=num_epochs)
    denoising_model = train_denoising_autoencoder(X_denoisingAE, Y_denoisingAE, 
                                                 num_epochs=num_epochs,
                                                 use_spectral_norm=False,  # Enable spectral normalization
                                                 use_residual=False)      # Enable residual connection
    assert random_sampling == False
    initial_state = ground_truth[0][:2]
    visualize_trajectories(bc_model, denoising_model, bc_augment_model, ground_truth, initial_state, num_steps=num_steps)

    # After training the models, add:
    print("\nVisualizing flow field...")
    # Calculate bounds based on the ground truth trajectory
    x_min, x_max = ground_truth[:, 0].min(), ground_truth[:, 0].max()
    y_min, y_max = ground_truth[:, 1].min(), ground_truth[:, 1].max()
    # Add some padding
    padding = 0.2
    bounds = ((x_min-padding, x_max+padding), (y_min-padding, y_max+padding))
    
    # visualize_flow_field(bc_model, denoising_model, bounds=bounds)

    # # After the flow field visualization, add:
    # print("\nVisualizing multiple trajectories comparison...")
    # # Use the initial state as the center point
    # center_point = initial_state
    # visualize_multiple_trajectories_comparison(bc_model, denoising_model, 
    #                                         ground_truth, center_point, 
    #                                         radius=0.05, num_trajectories=20, 
    #                                         num_steps=100)

    # # After the multiple trajectories comparison, add:
    # print("\nVisualizing local contraction comparison...")
    # visualize_local_contraction_comparison(bc_model, denoising_model, X_clean, 
    #                                      num_sample_points=15, num_local_samples=20, 
    #                                      radius=0.05)

    # After the previous visualizations, add:
    print("\nAnalyzing sensitivity and Lipschitz constants...")
    analyze_sensitivity_and_lipschitz(bc_model, denoising_model, X_clean, Y_clean,
                                    num_sample_points=10, num_local_samples=20,
                                    radius=0.01)

    print("\nAnalyzing sensitivity vs noise factor...")
    analyze_sensitivity_vs_noise(bc_model)

